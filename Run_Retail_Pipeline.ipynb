{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36800784-33d2-4245-9df7-32e84fea00b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, to_date, count, desc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "catalog = \"azure_databricks_personal\"\n",
    "schema = \"default\"\n",
    "volume_name = \"volume_checkpoints\"\n",
    "\n",
    "# 1. Create the Volume if it doesn't exist (THE FIX)\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog}.{schema}.{volume_name}\")\n",
    "\n",
    "# 2. Define paths\n",
    "source_path = \"/databricks-datasets/structured-streaming/events/\"\n",
    "checkpoint_base = f\"/Volumes/{catalog}/{schema}/{volume_name}/\"\n",
    "\n",
    "# --- 1. BRONZE LAYER (Ingest Raw Data) ---\n",
    "print(\"Starting Bronze Load...\")\n",
    "\n",
    "(spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    # This now points to a valid Volume\n",
    "    .option(\"cloudFiles.schemaLocation\", f\"{checkpoint_base}/bronze_schema\") \n",
    "    .load(source_path)\n",
    "    .withColumn(\"ingestion_time\", current_timestamp())\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", f\"{checkpoint_base}/bronze_adf\")\n",
    "    .option(\"mergeSchema\", \"true\")\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(f\"{catalog}.{schema}.bronze_events_adf\"))\n",
    "\n",
    "print(\"✅ Bronze Load Complete.\")\n",
    "\n",
    "# --- 2. SILVER LAYER ---\n",
    "print(\"Starting Silver Load...\")\n",
    "\n",
    "(spark.readStream\n",
    "    .table(f\"{catalog}.{schema}.bronze_events_adf\")\n",
    "    .select(\n",
    "        col(\"time\").cast(\"timestamp\").alias(\"event_time\"),\n",
    "        col(\"action\"),\n",
    "        to_date(col(\"time\").cast(\"timestamp\")).alias(\"event_date\"),\n",
    "        col(\"_rescued_data\")\n",
    "    )\n",
    "    .where(\"action IS NOT NULL\")\n",
    "    .writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", f\"{checkpoint_base}/silver_adf\")\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(f\"{catalog}.{schema}.silver_events_adf\"))\n",
    "\n",
    "print(\"✅ Silver Load Complete.\")\n",
    "\n",
    "# --- 3. GOLD LAYER ---\n",
    "print(\"Starting Gold Load...\")\n",
    "\n",
    "df_silver = spark.table(f\"{catalog}.{schema}.silver_events_adf\")\n",
    "\n",
    "df_gold = (df_silver\n",
    "    .groupBy(\"event_date\", \"action\")\n",
    "    .agg(count(\"*\").alias(\"action_count\"))\n",
    "    .orderBy(desc(\"event_date\")))\n",
    "\n",
    "df_gold.write.mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.gold_daily_summary_adf\")\n",
    "\n",
    "print(\"✅ Pipeline Finished Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea2252eb-866d-4f80-a93c-acb4d4eaacad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "cd \"/Workspace/Repos/tithirbakshi@outlook.com/azure-databricks-retail-lakehouse\"\n",
    "\n",
    "# 2. Force push\n",
    "git push -f origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b099eda1-f4d8-4099-8b61-18382b52f23a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5509551957758988,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Run_Retail_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
